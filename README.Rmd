---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# The dataset R Package

<!-- badges: start -->
[![lifecycle](https://lifecycle.r-lib.org/articles/figures/lifecycle-experimental.svg)](https://lifecycle.r-lib.org/articles/stages.html#experimental)
[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.6703765.svg)](https://doi.org/10.5281/zenodo.6703765)
[![Follow rOpenGov](https://img.shields.io/twitter/follow/ropengov.svg?style=social)](https://twitter.com/intent/follow?screen_name=ropengov) 
[![Follow author](https://img.shields.io/twitter/follow/digitalmusicobs.svg?style=social)](https://twitter.com/intent/follow?screen_name=digitalmusicobs)
<!-- badges: end -->

The goal of dataset is to create datasets from standared R objects (data.fame, data.table, tibble, or well-structured lists like json) that are highly interoperable and can be placed into relational databases, semantic web applications, archives, repositories.  They follow the [FAIR](https://www.go-fair.org/fair-principles/) principles: they are findable, accessible, interoperable and reusable. 

## Installation

You can install the development version of dataset from Github:

``` r
remotes::install_package(dataobservatory-eu/dataset)
```
## FAir: Findable & Accessible Datasets

If you work with R, you are almost certainly familiar with the iris dataset.  The *?iris* will provide you with some information about this often used dataset in tutorials. But how you make sure that you do not forget its important properties?

The function datacite [DataCite](https://datacite.org/) add at least the mandatory properties of the [DataCite Metadata Schema 4.3](https://schema.datacite.org/), a list of core metadata properties chosen for an accurate and consistent identification of a resource for citation and retrieval purposes. DataCite is largely interoperable to the other similar international standard, the [Dublin Core](https://www.dublincore.org/).  We will later add similar `dublincore` function, however, the practical differences are so small that adjustments, if needed, can be easily made by hand.

```{r datacite}
library(dataset)
iris_dataset <- datacite(
  df = iris,
  Title = "Iris Dataset",
  Creator = person("Anderson", "Edgar", role = "aut"),
  Publisher=" American Iris Society",
  PublicationYear = 1935,
  Description = "This famous (Fisher's or Anderson's) iris data set gives the measurements in centimeters of the variables sepal length and width and petal length and width, respectively, for 50 flowers from each of 3 species of iris. The species are Iris setosa, versicolor, and virginica.",
  Language = "en")
```

The `df` parameter can be any well-structured R object that meets the definition of a dataset: a data.frame, or an inherited class of it (data.table, [tibble](https://tibble.tidyverse.org/)); or a well-structured list (for example, a [json](https://arxiv.org/abs/1403.2805) object.)

```{r bibentry}
iris_bibentry <- dataset_bibentry(iris_dataset)
toBibtex(iris_bibentry)
```
```{r bibliography, results='asis'}
print(iris_bibentry, sytle="html")
```


## faIR: Interoperable & Reusable Datasets

The interoperability and reusability of datasets is greatly enhanced if they follow a standardized and practical format.  Our datasets follow the tidy data principles^[Wickham, H.(2014). Tidy Data. Journal of Statistical Software, 59(10), 1â€“23. <https://doi.org/10.18637/jss.v059.i10>] and are interoperable with the W3C ^[DF Data Cube Vocabulary]^[RDF Data Cube Vocabulary, W3C Recommendation 16 January 2014  <https://www.w3.org/TR/vocab-data-cube/#metadata>] (semantic web) and SDMX (statistical) dataset definitions.

Both W3C and SDMX uses are more complex object, the Datacube in its description. The dataset is a redused datacube. To adhere to tidy data principles and easy use in reproducible resaerch workflows, we further reduced our subjective definition of the dataset. 

- The `dataset` constructor first subsets the dataset for the `obs_id` observation identifier, and if it is missing, it creates one.
- Then it selects the `dimensions`, such as geographic concept or time concept. The iris dataset does not have these variables, so we do not select anything.
- Next we select the `measurements`.  In case only one `measurement` is present, we have a long-form dataset that can be easily serialized into an `RDF` object, for example. 
- Next we select any `attributes` that are unlikely to be used for statistical aggregation (unlike the dimensions) and which are not measured values. 
- We can pass on further optional dataset attributes. These attributes do not correspond with a single observation, rather the entire dataset.

```{r}
petal_length <- dataset(iris, 
        obs_id = NULL, 
        dimensions=NULL, 
        measurements = "Petal.Length", 
        attributes = "Species", 
        Title = "Iris Subset", unit = "mm", 
        Publisher = "Reprex")

petal_width <- dataset(iris, 
        obs_id = NULL, 
        dimensions=NULL, 
        measurements = "Petal.Width", 
        attributes = "Species", 
        Title = "Iris Subset", unit = "mm", 
        Publisher = "Reprex")

require(dplyr)
petal_length %>% left_join (petal_width, by = c("obs_id", "Species"))
```
The obvious motivation of this format is that the datasets can be easily integrated, joined, combined, because they are tidy.

In a the long form, they easily lend themselves for RDF format:

```{r}
names(petal_width)[2] <- "measurement"
petal_width$petal_dimension <- "Petal width"
names(petal_length)[2] <- "measurement"
petal_length$petal_dimension <- "Petal length"

head(use_function(petal_width,  .f = "rbind", y = petal_length))

```


- `obs_id`: The unique identifier of the observations. If they are not present, the row.names() will be used---R row names may be lost when exporting to non-R files and it is better to make them explicit. In a tidy dataset there are exactly one observation identifier, because each row represents an observation.
- `dimensions`: Variables that can be used for aggregation, for examaple, around a geographical concept like countries. The most important dimensions are a geographical concept (where was the measurement made) and a time concept (when was the measurement made, or what is the reference time period.)
- `measurements`: Actual measurements of the observations.
- `attributes`: Non-measured attributes, categories or constants.
- `unit`: The unit of the measurement(s). In the tidy data defintion, each table has only one unit, measurements in different units go into different tables.
- `dataset_id`:  The identifier of the dataset. When joining datasets, it may be desirable to keep the unit observation ids. The `dataset_id` and the `obs_id` will be used to create unique resource identifiers (URIs). 


## Reproducible Datasets

```{r dataset}
population_dataset <- dataset::read_dataset(
  "demo_pjan", Title = "Population of Select Countries",
  dimensions = c("age", "sex", "geo", "time"), 
  measurements = "values", 
  attributes = NULL,
  unit = "NR",
  .f = "eurostat::get_eurostat",
  id = "demo_pjan",
  
  filters = list(
    unit = "NR",
    age=  c("TOTAL", "Y_LT1"), 
    geo = c("UK", "XK", "AT"), 
    time = c(2010:2020)
  )
)

summary_population <- use_function(dataset = population_dataset, .f = "summary")
```

If your application needs URIs, the first 5 elements of the iris dataset can be referenced as `dataset_id#obs_id` will be used to create unique resource identifiers (URIs). For the first five observations of the `population_dataset` dataset: `r paste("population_dataset", 1:5, sep="#", collapse ="','")`

```{r}
knitr::kable(attr(summary_population, "Date"))
```

```{r}
attr(population_dataset, "RelatedIdentifier")
```


## Code of Conduct

Please note that the StatCodelists project is released with a [Contributor Code of Conduct](https://contributor-covenant.org/version/2/1/CODE_OF_CONDUCT.html). By contributing to this project, you agree to abide by its terms.
